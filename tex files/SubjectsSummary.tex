\documentclass[12pt]{matmex-diploma}
\usepackage{xcolor}
\usepackage{hyperref}	
\usepackage{enumitem}
\usepackage{minted}
\usepackage{amsfonts}
\setlist{nolistsep}
\definecolor{urlcolor}{HTML}{0e0b61}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,      
    urlcolor=urlcolor,
    pdftitle={Sharelatex Example},
    pdfpagemode=FullScreen,
}

\begin{document}

\tableofcontents

\section{Математика} 


    \subsection{Математический анализ}

        \subsubsection*{Предел}
        
            \textbf{Предел последовательности}
            
            Число A будем называть \textbf{пределом последовательности} $\left\{ x_n \right\}_{n=1}^{n=\infty}$, если для любого $\varepsilon>0$ можно найти номер $n_0 = n_0\left( \varepsilon \right)$ (зависящий от $\varepsilon$), начиная с которого все члены последовательности будут удовлетворять неравенству $|x_n - A|<\varepsilon$.
            
            \textbf{Обозначается}: $\lim_{n \to \infty}x_n = A$
            
            $\forall \varepsilon>0, \; \exists n_0 = n_0(\varepsilon) , \; \forall n > n_0: |x_n - A|<\varepsilon$
            
            \textbf{Предел функции}
            
            \textbf{Определение предела функции по Коши}
            
            Число A называется \textbf{пределом функции} $f(x)$ при x, стремящемся к $x_0$ (или в точке $x_0$), если для любого $\varepsilon>0$ можно найти число $\delta=\delta(\varepsilon)>0$ так, что для всех значений $x \in D(f)$, для которых выполнено неравенство $0<|x - x_0|<\delta$, справедливо неравенство $|f(x) - A|<\varepsilon$.
            
            Обозначается: $\lim_{x \to x_0}f(x) = A$
            
            $\forall \varepsilon>0, \; \exists \delta=\delta(\varepsilon)>0 : \forall x \;  0<|x - x_0|<\delta \Rightarrow |f(x) - A| < \varepsilon$
            
            \textbf{Определение предела функции по Гейне}
            
            Число A называется \textbf{пределом функции} $f(x)$ при x, стремящемся к $x_0$ (или в точке $x_0$), если для любой последовательности $\left\{ x_n \right\}$ точек, взятых из области определения функции, сходящейся к $x_0$, но не содержащей $x_0$ в качестве одного из своих элементов, последовательность значений функции $f(x_n)$ будет стремиться к числу A.
            
            
        \subsubsection*{Обозначения O() и o()}
            
            Пусть $f(x)$ и $g(x)$ — две функции, определенные в некоторой проколотой окрестности точки $x_0$, причем в этой окрестности g не обращается в ноль. Говорят, что:
                \begin{itemize}
                \item $f$ является «O» большим от $g$ при $x \to x_0$, если существует такая константа $C > 0$, что для всех $x$ из некоторой окрестности точки $x_0$ имеет место неравенство: $|f(x)|\leq C|g(x)|$;
                \item $f$ является «о» малым от $g$ при $x \to x_0$, если для любого $\varepsilon>0$ найдется такая проколотая окрестность $U'_{x_0}$ точки $x_0$, что для всех $x \in U'_{x_0}$ имеет место неравенство: $|f(x)| < \varepsilon|g(x)|$.
                \end{itemize} 
            
            Иначе говоря, в первом случае отношение ${|f| \over |g|} \leq C$ в окрестности точки $x_0$(то есть ограничено сверху), а во втором оно стремится к нулю при $x \to x_0$.
            
            Запись $x^2 = o(x)$ означает, что $x^2$ при $x \to 0$ является бесконечно малой функцией более высокого порядка, по сравнению с функцией $x$.
            
        \subsubsection*{Доказательство и применение асимптотических оценок, при необходимости переформулировка в «терминах эпсилон и дельта»}
            
            Если $\lim_{x \to a}{f(x) \over g(x)} = 0$, то говорят, что \textbf{$f(x) = o(g(x))$} при $x \to a$.
            
            Например, $x^2 = o(x)$ при $x \to 0$, поскольку $\lim_{x \to 0}{{x^2} \over x} = \lim_{x \to 0}{x} = 0$.
            
            Если предел отношения $|f(x)| \over |g(x)|$ при $x \to a$ конечен, то \textbf{$f(x) = O(g(x))$} при $x \to a$.
            
            Например, $x + x^2 = O(x)$ при $x \to 0$, поскольку $\lim_{x \to 0}{{x + x^2} \over x} = \lim_{x \to 0}{1+x} = 1$.
            
        \subsubsection*{Непрерывность}
        
            \textbf{Непрерывность в точке:}
            
            \textbf{Определение 1:}
            Пусть $x_0 \in D(f)$ - предельная точка области определения функции $f(x)$. (Предельная точка множества — это такая точка, любая проколотая окрестность которой пересекается с этим множеством.)  Будем говорить, что функция $f(x)$ \textbf{непрерывна} в точке $x_0$, если $\lim_{x \to x_0}f(x) = f(x_0)$.
            
            Если точка $x_0$ является предельной точкой области $D(f)$, но функция не является непрерывной в этой точке, то точка $x_0$ называется \textbf{точкой разрыва} функции $f(x)$.
            
            \textbf{Определение 2:}
            Функция $f(x)$ \textbf{непрерывна} в точке $x_0$, если $\lim_{x \to x_0^{-0}}f(x) = \lim_{x \to x_0^{+0}}f(x)  = f(x_0)$.
            
            Если односторонние пределы в точке $x_0$ существуют и равны между собой, но функция в этой точке не определена или $f(x_0) \neq  \lim_{x \to x_0^{-0}}f(x) = \lim_{x \to x_0^{+0}}f(x)$, то точка $x_0$ называется \textbf{точкой устранимого разрыва}.
            
            Если существуют конечные односторонние пределы, но они не равны между собой, то точка $x_0$, называется \textbf{точкой разрыва первого рода}.
            
            Если в точке $x_0$ хотя бы один конечный односторонний предел не существует или существует и бесконечен, то эта точка называется \textbf{точкой разрыва второго рода}.
            
            \textbf{Критерий непрерывности функции в точке:}
            
            Функция $f(x)$ будет непрерывной в точке $x_0$ тогда и только тогда, когда ее приращение в этой точке будет стремиться к нулю, если приращение аргумента стремится к нулю.
            
            Если $\bigtriangleup x \to 0$, то $\bigtriangleup f(x_0) \to 0$.
            
            \textbf{Непрерывность на множестве:}
            
            \textbf{Определение:}
            Будем говорить, что функция $f(x)$ непрерывна на множестве, если она непрерывна в каждой точке этого множества.
            
            \textbf{Первая теорема Вейерштрасса: }
            Функция, непрерывная на отрезке, ограничена.
            
            \textbf{Вторая теорема Вейерштрасса: }
            Если функция непрерывна на отрезке, то на этом отрезке она достигает своих наибольшего и наименьшего значений.
            
            \textbf{Первая теорема Коши о промежуточном значении непрерывной на отрезке функции: }
            Пусть функция $f(x)$ непрерывна на отрезке $\left[ {a , b} \right]$ и на концах этого отрезка принимает значения разных знаков. Тогда внутри отрезка найдется, по крайней мере,одна точка, в которой $f(x) = 0$. 
            
            \textbf{Равномерная непрерывность:}
            
            Числовая функция вещественного переменного $f \colon M \subset \mathbb R \to \mathbb R$ равномерно непрерывна, если:
            $\forall \varepsilon>0, \; \exists \delta=\delta(\varepsilon)>0 : \forall x_1, x_2 \in M \; (|x_1 - x_2| < \delta) \Rightarrow (|f(x_1) - f(x_2)| < \varepsilon)$.
            
        \subsubsection*{Производная}
        
            Пусть функция $y=f(x)$  определена в некоторой окрестности точки $x_0$. Допустим, что существует предел отношения приращения функции в этой точке к вызвавшему его приращению аргумента, когда последнее стремится к нулю: $\lim_{\bigtriangleup x \to 0}{{f(x_0 + \bigtriangleup x) - f(x_0)} \over \bigtriangleup x}$.Тогда этот предел называется \textbf{производной} функции в точке $x_0$.
            
            Т.о. $f'(x_0) = \lim_{\bigtriangleup x \to 0}{{f(x_0 + \bigtriangleup x) - f(x_0)} \over \bigtriangleup x} = \lim_{\bigtriangleup x \to 0}{{\bigtriangleup f(x_0)} \over \bigtriangleup x}$.
            
        \subsubsection*{Первообразная}
        
            \textbf{Первообразной} для данной функции $f(x)$  называют такую функцию $F(x)$, производная которой равна f (на всей области определения f), ), то есть $F'(x) = f(x)$.
            
        \subsubsection*{Дифференциал}
        
            \textbf{Дифференциал функции одной переменной:}
        
            Функция f (x) называется \textbf{дифференцируемой} в точке $x_0$ , если существует число A такое, что $ \bigtriangleup f(x_0) = A \bigtriangleup x + o(\bigtriangleup x) $ при $\bigtriangleup x \to 0$.
            
            Допустим, что функция $f(x)$ дифференцируема в точке $x_0$. Тогда выражение $f'(x_0)\bigtriangleup x$ будем называть \textbf{дифференциалом} этой функции в точке $x_0$ и обозначать $df(x_0)$ или $df$.
            
            \textbf{Дифференциал функции многих переменных:}
            
            Пусть есть функция $f(x_1 ... x_n)$, дифференцируемая в точке $a(x_1 ... x_n)$, тогда её дифференциалом будет:
            $df = {\partial f \over \partial x_1}dx_1 + {\partial f \over \partial x_2}dx_2 + ... + {\partial f \over \partial x_n}dx_n$, где $dx_i = \bigtriangleup x_i$.
            
        \subsubsection*{Нахождение экстремума функции от одной и от многих переменных}
            
            \textbf{Нахождение экстремума функции от одной переменной:}
            
            Точка $x_0$ называется \textbf{точкой локального максимума(минимума)} функции $f(x)$, если существует такая окрестность этой точки, что для всех $x$ из этой окрестности выполняется неравенство: $f(x) \leq f(x_0)$ ($f(x) \geq f(x_0)$).
            
            \textbf{Необходимое условие экстремума:}
            Если функция $y = f(x)$ имеет экстремум в точке $x_0$, то ее производная $f'(x_0)$ либо равна нулю, либо не существует.
            
            \textbf{Первое достаточное условие экстремума:}
            Пусть для функции $y = f(x)$ выполнены следующие условия:
            \begin{itemize}
                \item функция непрерывна в окрестности точки $x_0$;
                \item $f'(x_0) = 0$ или $f'(x_0)$ не существует;
                \item производная $f'(x)$ при переходе через точку $x_0$ меняет свой знак.
            \end{itemize}
            
            Тогда в точке $x = x_0$ функция $y = f(x)$ имеет экстремум, причем это \textbf{минимум}, если при переходе через точку $x_0$ производная меняет свой знак с минуса на плюс; \textbf{максимум}, если при переходе через точку $x_0$ производная меняет свой знак с плюса на минус.
            
            \textbf{Второе достаточное условие экстремума:}
            Пусть для функции $y = f(x)$ выполнены следующие условия:
            \begin{itemize}
                \item она непрерывна в окрестности точки $x_0$;
                \item $f'(x_0) = 0$;
                \item $f''(x_0) \neq 0$.
            \end{itemize}
            
            Тогда в точке $x_0$ достигается экстремум, причем, если $f''(x_0) > 0$, то в точке $x = x_0$ функция $y = f(x)$ имеет \textbf{минимум}; если $f''(x_0) < 0$, то в точке $x = x_0$ функция $y = f(x)$ достигает \textbf{максимум}.
            
            \textbf{Нахождение экстремума функции от многих переменных:}
            
            Пусть функция $f(x_1 ... x_n)$ определена на множестве $E \in R^n$ и точка $x^0 \in E$. Точка $x^0$  называется \textbf{точкой локального минимума (максимума)} функции $f(x_1 ... x_n)$ если$ \exists U(x^0) : \forall x \in U(x^0) \cap E : f(x) \geq f(x^0)(f(x) \leq f(x^0))$.
            
            \textbf{Необходимое условие экстремума:}
            Пусть функция $f(x_1 ... x_n)$ определена в $U(x^0)$ и имеет локальный экстремум в точке $x_0$. Если $\exists {\partial f \over \partial x_k} (x^0) $, $1 \leq k \leq n$, то ${\partial f \over \partial x_k} (x^0) = 0 \; \forall k = 1...n$.
            
            \textbf{Достаточное условие экстремума:}
            Пусть функция $f(x_1 ... x_n)$ определена в $U(x^0)$ и имеет в этой окрестности непрерывные частные производные второго порядка. Пусть $df(x^0) = 0$. Если $d^2f(x^0)$ является знакоопределенной квадратичной формой, тогда $x^0$ - \textbf{точка локального экстремума}, причем если $d^2f(x^0) > 0$, то $x^0$ - \textbf{локальный минимум}, а если $d^2f(x^0) < 0$, то $x^0$ - \textbf{локальный максимум}.
            
        \subsubsection*{Формула Тейлора}
        
            Если функция $f(x)$ имеет $n+1$ производную на отрезке с концами $a$ и $x$, то для произвольного положительного числа $p$ найдётся точка $\xi$, лежащая между $a$ и $x$, такая, что (или пусть действительная функция f определена в некоторой окрестности точки $a$): 
            $f(x) = \sum_{k=0}^n {{f^{(k)}(a)} \over k!}(x-a)^k + {\left({x-a} \over {x - \xi}\right)^p {(x- \xi)^{n+1} \over n!p}f^{(n+1)}(\xi)}$.
        
    \subsection{Дискретная математика и математическая логика}
    
        \subsubsection*{Отображения и отношения и их свойства}
             Бинарное отношение на множестве $A$ — любое подмножество $R\subseteq A^{2}=A\times A$. Примерами служат равенство, неравенство, эквивалентность
            
        \subsubsection*{Транзитивное замыкание отношения}
            Транзитивное замыкание в теории множеств — это операция на бинарных отношениях. Транзитивное замыкание бинарного отношения $R$ на множестве $X$ есть наименьшее транзитивное отношение на множестве $X$, включающее $R$.
            
            Пусть множество $A$ представляет собой следующее множество деталей и конструкций: $A$ = \{Болт, Гайка, Двигатель, Автомобиль, Колесо, Ось\}, причем некоторые из деталей и конструкций могут использоваться при сборке других конструкций. Взаимосвязь деталей описывается отношением $R$(«непосредственно используется в») и состоит из следующих кортежей:

            \begin{table}[htb]
                \centering
                \begin{tabular}{|c|c|}
                    \hline
                    \textbf{Конструкция} & \textbf{Где используется} \\ \hline
                    Болт                 & Двигатель                 \\ \hline
                    Болт                 & Колесо                    \\ \hline
                    Гайка                & Двигатель                 \\ \hline
                    Гайка                & Колесо                    \\ \hline
                    Двигатель            & Автомобиль                \\ \hline
                    Колесо               & Автомобиль                \\ \hline
                    Ось                  & Колесо                    \\ \hline
                \end{tabular}
                \caption{Отношение $R$.}
            \end{table}

            Очевидный смысл замыкания $R$ состоит в описании включения деталей друг в друга не только непосредственно, а через использование их в промежуточных деталях, например, болт используется в автомобиле, так как он используется в двигателе, а двигатель используется в автомобиле.
            
            Транзитивное замыкание состоит из кортежей (добавленные кортежи помечены жирным):

            \begin{table}[htb]
                \centering
                \begin{tabular}{|c|c|}
                    \hline
                    \textbf{Конструкция} & \textbf{Где используется} \\ \hline
                    Болт                 & Двигатель                 \\ \hline
                    Болт                 & Колесо                    \\ \hline
                    Гайка                & Двигатель                 \\ \hline
                    Гайка                & Колесо                    \\ \hline
                    Двигатель            & Автомобиль                \\ \hline
                    Колесо               & Автомобиль                \\ \hline
                    Ось                  & Колесо                    \\ \hline
                    \textbf{Болт}        & \textbf{Автомобиль}       \\ \hline
                    \textbf{Гайка}       & \textbf{Автомобиль}       \\ \hline
                    \textbf{Ось}         & \textbf{Автомобиль}       \\ \hline
                \end{tabular}
                \caption{Транзитивное замыкание отношения $R$.}
            \end{table}            
                            
        \subsubsection*{Эквивалентность}
            Отношение эквивалентности $(\sim)$ на множестве $X$ — это бинарное отношение, для которого выполнены следующие условия:
            \begin{itemize}
                \item рефлексивность: $a\sim a$ для любого $a$ в $X$;
                \item симметричность: если $a\sim b$, то $b\sim a$;
                \item транзитивность: если $a\sim b$ и $b\sim c$, то $a\sim c$.
            \end{itemize}

            Запись вида «$a\sim b$» читается как «$a$ эквивалентно $b$».
            
            Пример: Сравнение по модулю, $a \equiv b \pmod n$.
            
        \subsubsection*{Отношения порядка}
            Бинарное отношение $R$ на множестве $X$ называется отношением нестрогого частичного порядка (отношением порядка, отношением рефлексивного порядка), если имеют место:
            \begin{itemize}
                \item Рефлексивность: $\forall x: xRx$;
                \item Антисимметричность: $\forall x, y: x R y \land y R x \Rightarrow x = y$;
                \item Транзитивность: $\forall x,y,z: x R y \land y R z \Rightarrow x R z$.
            \end{itemize}

            Множество $X$, на котором введено отношение частичного порядка, называется частично упорядоченным.
            
            Пример: На множестве вещественных чисел отношения «больше» и «меньше» являются отношениями строгого порядка, а «больше или равно» и «меньше или равно» — нестрогого.
            
        \subsubsection*{Логика высказываний}
            1
        \subsubsection*{Кванторы}
            Квантор — общее название для логических операций, ограничивающих область истинности какого-либо предиката и создающих высказывание. Чаще всего упоминают:
            \begin{itemize}
                \item Квантор всеобщности (обозначение: $\forall$ , читается: «для любого…», «для каждого…», «для всех…» или «каждый…», «любой…», «все…»).
                \item Квантор существования (обозначение: $\exists$ , читается: «существует…» или «найдётся…»).
            \end{itemize}
            
        \subsubsection*{Метод математической индукции}
            1
        \subsubsection*{Основные понятия теории графов}
        
            \textbf{Ориентированные графы}
            
            \textbf{Ориентированным графом} $G$ называется пара $G = (V, E)$, где $V$ — множество вершин, а $E \subset V \times V$ — множество рёбер.
            
            \textbf{Ребром} ориентированного графа называют упорядоченную пару вершин $(v, u) \in E$.
            
            В графе ребро, концы которого совпадают, то есть $e = (v,v)$, называется \textbf{петлей}.
            
            Два ребра, имеющие общую концевую вершину, то есть $e_1 = (v,u_1)$ и $e_2 = (v,u_2)$, называются \textbf{смежными}.
            
            Если имеется ребро $(v, u) \in E$, то говорят:
            \begin{itemize}
                \item $v$ - \textbf{предок} $u$;
                \item $u$ и $v$ — \textbf{смежные};
                \item Вершина $u$ \textbf{инцидентна} ребру $(v, u)$;
                \item Вершина $v$ \textbf{инцидентна} ребру $(v, u)$.
            \end{itemize} 
            
            \textbf{Кратные рёбра} - это два и более рёбер, инцидентных одним и тем же двум вершинам.
            
            \textbf{Неориентированные графы}
            
            \textbf{Неориентированным графом} $G$ называется пара $G = (V, E)$, где $V$ — множество вершин, а $E \subset \left\{ {\left\{ v, u \right\}} : v,u \in V \right\}$ — множество рёбер.
            
            \textbf{Ребром} в неориентированном графе называют неупорядоченную пару вершин ${\left\{ v, u \right\}} \in E$.
            
            \textbf{Простым графом} $G$ называется граф, в котором нет петель и кратных рёбер.
            
            \textbf{Степенью} вершины $deg v_i$ в неориентированном графе называют число рёбер, инцидентных $v_i$.
            
            \textbf{Изолированной вершиной} в неориентированном графе называют вершину степени 0.
            
            \textbf{Часто используемые графы}
            
            \textbf{Полный граф} — граф, в котором каждая пара различных вершин смежна.
            
            \textbf{Регулярный граф} — граф, степени всех вершин которого равны, то есть каждая вершина имеет одинаковое количество соседей.
            
            \textbf{Плана́рный граф} — граф, который может быть изображён на плоскости без пересечения рёбер. Иначе говоря, граф планарен, если он изоморфен некоторому плоскому графу, то есть графу, изображённому на плоскости так, что его вершины — это точки плоскости, а рёбра — непересекающиеся кривые на ней.
          
            \textbf{Ещё полезные определения:}
            
            \textbf{Маршрут }— чередующаяся последовательность вершин и рёбер $v_0, e_1, v_1, e_2, v_2,...,e_k,v_k$ , в которой любые два соседних элемента инцидентны. Если $v_0 = v_k$, то маршрут замкнут, иначе открыт.
            
            \textbf{Путь} — последовательность рёбер (в неориентированном графе) и/или дуг (в ориентированном графе), такая, что конец одной дуги (ребра) является началом другой дуги (ребра).
            
            \textbf{Простой (вершинно-простой) путь} — путь, в котором каждая из вершин графа встречается не более одного раза.
            
            \textbf{Рёберно-простой путь} — путь, в котором каждое из рёбер графа встречается не более одного раза.
            
            \textbf{Цикл} - замкнутый маршрут, все рёбра которого различны.
            
            \textbf{Эйлеровым путем} в графе называется путь, который проходит по каждому ребру, причем ровно один раз.
            
            \textbf{Эйлеров цикл} — замкнутый эйлеров путь.
            
            Граф называется \textbf{эйлеровым}, если он содержит эйлеров цикл.
            
            \textbf{Гамильтоновым путём} называется простой путь, проходящий через каждую вершину графа ровно один раз.(и дальше по аналогии со всем эйлеровым)
            
        \subsubsection*{Лемма о рукопожатиях}
        
            \textbf{Неориентированный граф}
            
            \textbf{Лемма:}
            Сумма степеней всех вершин графа — чётное число, равное удвоенному числу рёбер:
            $\sum_{v \in V(G)} deg v = 2*|E(G)|$
            
            \textbf{Следствие:}
            Число рёбер в полном графе ${n*(n-1)} \over 2$.
            
            \textbf{Ориентированный граф}
            
            \textbf{Лемма:}
            Сумма входящих и исходящих степеней всех вершин ориентированного графа — чётное число, равное удвоенному числу рёбер: 
            $\sum_{v \in V(G)} deg^- v + \sum_{v \in V(G)} deg^+ v = 2*|E(G)|$
            
        \subsubsection*{Критерий двудольности}
        
            \textbf{Двудольный граф} — граф, множество вершин которого можно разбить на две части таким образом, что каждое ребро графа соединяет какую-то вершину из одной части с какой-то вершиной другой части, то есть не существует ребра, соединяющего две вершины из одной и той же части. 
            
            \textbf{Двудольный граф} с $n$ вершинами в одной доле и $m$ во второй обозначается $K_{n,m}$.
            
            \textbf{Критерий двудольности}
            Граф является \textbf{двудольным} тогда и только тогда, когда он содержит более одной вершины и все его циклы имеют четную длину.
            
        \subsubsection*{Оценки числа ребер}
            
            \begin{itemize}
                \item Число рёбер в \textbf{полном графе} ${n*(n-1)} \over 2$.
                \item Максимальное число ребер на $n$ вершинах можно построить именно в случае, когда граф связный.
                \item Любое дерево с $n$ вершинами содержит $n-1$ ребро.
                \item Не забываем про лемму о рукопожатиях.
                \item Если речь идет о двудольных графах, полезно помнить, что число ребер в полном двудольном графе с $n_1$ и $n_2$ вершинами в соответствующих долях равно $n_1*n_2$.
            \end{itemize}
            
        \subsubsection*{Характеризация деревьев}    
        
            \textbf{Дерево} — связный ациклический граф.Связность означает наличие путей между любой парой вершин, ацикличность — отсутствие циклов и то, что между парами вершин имеется только по одному пути.
            
            \textbf{Лес} — граф, являющийся набором непересекающихся деревьев.
            
            \textbf{Остовное дерево} — ациклический связный подграф данного связного неориентированного графа, в который входят все его вершины.
            
            \textbf{N-арные деревья:}
            \begin{itemize}
                \item N-арное дерево (неориентированное) — это дерево (обычное, неориентированное), в котором степени вершин не превосходят $N+1$.
                \item N-арное дерево ориентированное) — это ориентированное дерево, в котором исходящие степени вершин (число исходящих рёбер) не превосходят $N$.
            \end{itemize}
        
    \subsection{Алгебра и теория чисел}
        
        \subsubsection*{Группы}
            Непустое множество G с заданной на нём бинарной операцией $*:\mathrm{G} \times \mathrm{G} \rightarrow \mathrm{G}$ называется группой $(\mathrm {G} ,*)$, если выполнены следующие аксиомы:
            \begin{enumerate}
                \item ассоциативность: \\$\forall (a,b,c\in G)\colon (a*b)*c=a*(b*c)$;
                \item наличие нейтрального элемента: \\$\exists e\in G\quad \forall a\in G\colon (e*a=a*e=a)$;
                \item наличие обратного элемента: \\$\forall a\in G\quad \exists a^{-1}\in G\colon (a*a^{-1}=a^{-1}*a=e)$.
            \end{enumerate}
            
        \subsubsection*{Поля}
            Множество $F$ с введёнными на нём алгебраическими операциями сложения $+$ и умножения $*$ ($+\colon F\times F\to F,\quad *\colon F\times F\to F$, т. е. $\forall a,b\in F\quad (a+b)\in F,\;a*b\in F$) называется полем $\left\langle F,+,*\right\rangle$, если выполнены следующие аксиомы:
            \begin{enumerate}
                \item Коммутативность сложения: \\$\forall a,b\in F\quad a+b=b+a$.
                \item Ассоциативность сложения: \\$\forall a,b,c\in F\quad (a+b)+c=a+(b+c)$.
                \item Существование нулевого элемента: \\$\exists{0}\in F\colon \forall a\in F\quad a+{0}={0}+a=a$.
                \item Существование противоположного элемента: \\$\forall a\in F\;\exists (-a)\in F\colon a+(-a)={0}$.
                \item Коммутативность умножения: \\$\forall a,b\in F\quad a*b=b*a$.
                \item Ассоциативность умножения: \\$\forall a,b,c\in F\quad (a*b)*c=a*(b*c)$.
                \item Существование единичного элемента: \\$\exists e\in F\setminus \{{0}\}\colon \forall a\in F\quad a*e=a$.
                \item Существование обратного элемента для ненулевых элементов: \\$\forall a\in F\colon a\neq {0})\;\exists a^{-1}\in F\colon a*a^{-1}=e$.
                \item Дистрибутивность умножения относительно сложения: \\$\forall a,b,c\in F\quad (a+b)*c=(a*c)+(b*c)$.
            \end{enumerate}            
            
        \subsubsection*{Кольца}
            Множество $R$, на котором заданы две бинарные операции: $+$ и $*$ (называемые сложение и умножение), со следующими свойствами, выполняющимися для любых $a, b, c \in R$:
            \begin{enumerate}
                \item Коммутативность сложения: \\$a+b=b+a$.
                \item Ассоциативность сложения: \\$(a+b)+c=a+(b+c)$.
                \item Существование нулевого элемента: \\$\exists{0}\in R\colon a+{0}={0}+a=a$.
                \item Существование противоположного элемента: \\$\forall a\in R\;\exists (-a)\in R\colon a+(-a)={0}$.
                \item Ассоциативность умножения: \\$(a*b)*c=a*(b*c)$.
                \item Дистрибутивность: \\$\begin{matrix}a* (b+c)=(a*b)+(a*c)\\(b+c)*a=(b*a)+(c*a)\end{matrix}$.
            \end{enumerate}             
            
        \subsubsection*{Факторизация}
            Факторизацией натурального числа называется его разложение в произведение простых множителей. Может быть выполнена, например, \textbf{перебором возможных делителей}. Способ заключается в том, чтобы последовательно делить факторизуемое число $n$ на натуральные числа от $1$ до $\lfloor {\sqrt {n}}\rfloor$. Формально достаточно делить только на простые числа в этом интервале, однако, для этого необходимо знать их множество. На практике составляется таблица простых чисел и производится проверка небольших чисел (например, до $2^{16}$). Для очень больших чисел алгоритм не используется в силу низкой скорости работы.
            
        \subsubsection*{Идеал}
            Для кольца $R$ идеалом называется подкольцо, замкнутое относительно умножения на элементы из $R$.
        
            Идеалом кольца $R$ называется такое подкольцо (подкольцо кольца $(K,+,*)$ рассматривается как подмножество $R\subset K$, замкнутое относительно операций $+$ и $*$ из основного кольца) $I$ кольца $R$, что
            \begin{enumerate}
                \item $\forall i\in I\;\forall r\in R$ произведение $ir\in I$ (условие на правые идеалы);
                \item $\forall i\in I\;\forall r\in R$ произведение $ri\in I$ (условие на левые идеалы);
            \end{enumerate}             
            
        \subsubsection*{Сравнения}
            Если два целых числа $a$ и $b$ при делении на $m$ дают одинаковые остатки, то они называются сравнимыми (или равноостаточными) по модулю числа $m$.
            
            Сравнимость чисел $a$ и $b$ записывается в виде формулы (сравнения): $$a\equiv b{\pmod  {m}}$$. Число $m$ называется модулем сравнения.
            
        \subsubsection*{Алгоритм Евклида}
            Алгоритм Евклида – эффективный алгоритм для нахождения наибольшего общего делителя двух целых чисел.
            
            Пусть $a$ и $b$ — целые числа, не равные одновременно нулю, и последовательность чисел $a>b>r_{1}>r_{2}>r_{3}>r_{4}>\ \dots \ >r_{n}$ определена тем, что каждое $r_{k}$ — это остаток от деления предпредыдущего числа на предыдущее, а предпоследнее делится на последнее нацело, то есть:
            \\$a=bq_{0}+r_{1}$,
            \\$b=r_{1}q_{1}+r_{2}$,
            \\$r_{1}=r_{2}q_{2}+r_{3}$,
            \\$\cdots$ 
            \\$r_{k-2}=r_{k-1}q_{k-1}+r_{k}$,
            \\$\cdots $
            \\$r_{n-2}=r_{n-1}q_{n-1}+r_{n}$,
            \\$r_{n-1}=r_{n}q_{n}$.
            
            Тогда НОД$(a, b)$, наибольший общий делитель $a$ и $b$, равен $r_{n}$, последнему ненулевому члену этой последовательности.
            
        \subsubsection*{Теоремы Эйлера и Ферма}
            \textbf{Теорема Эйлера:} если $a$ и $m$ взаимно просты, то $a^{\varphi(m)} \equiv 1 \pmod m$, где $\varphi(m)$ — функция Эйлера (количество натуральных чисел, меньших $m$ и взаимно простых с ним).
            
            \textbf{Малая теорема Ферма:} если $a$ не делится на простое число $p$, то \\$a^{{p-1}}\equiv 1{\pmod  p}$.
            
        \subsubsection*{Кольцо многочленов}
            \textbf{Многочлен} от $x$ с коэффициентами в поле $k$ — это выражение вида $p=p_{m}x^{m}+p_{m-1}x^{m-1}+\dots +p_{1}x+p_{0}$, где $p_0, \dots, p_m$ — элементы $k$, коэффициенты $p, a, x, x^{2}, \dots$ — формальные символы («степени x»). Такие выражения можно складывать и перемножать по обычным правилам действий с алгебраическими выражениями (коммутативность сложения, дистрибутивность, приведение подобных членов и т. д.). Члены $p_kx^{k}$ с нулевым коэффициентом $p_k$ при записи обычно опускаются. Используя символ суммы, многочлены записывают в более компактном виде: \\$p=p_{m}x^{m}+p_{m-1}x^{m-1}+\dots +p_{1}x+p_{0}=\sum _{k=0}^{m}p_{k}x^{k}$.
            
            Множество всех многочленов с коэффициентами в $k$ образует коммутативное кольцо, обозначаемое $k[x]$ и называемое \textbf{кольцом многочленов} над $k$.
            
        \subsubsection*{Число корней многочлена}
            Корень многочлена (не равного тождественно нулю) $a_{0}+a_{1}x+\dots +a_{n}x^{n}$ над полем K — это элемент $c\in K$ (либо элемент расширения поля K), такой, что выполняются два следующих равносильных условия:
            \begin{itemize}
                \item данный многочлен делится на многочлен $x-c$;
                \item подстановка элемента c вместо x обращает уравнение \\$a_{0}+a_{1}x+\dots +a_{n}x^{n}=0$ в тождество.
            \end{itemize}   
            
            Число корней многочлена степени $n$ не превышает $n$ даже в том случае, если кратные корни учитывать кратное количество раз.

        \subsubsection*{Линейные пространства и операторы}
            \textbf{Линейное пространство} $V\left(F\right)$ над полем $F$ — это упорядоченная четвёрка $(V,F,+,\cdot )$, где
            \begin{itemize}
                \item $V$ — непустое множество элементов произвольной природы, которые называются векторами;
                \item $F$ — поле, элементы которого называются скалярами;
                \item Определена операция сложения векторов $V\times V\to V$, сопоставляющая каждой паре элементов $\mathbf {x} ,\mathbf {y}$ множества $V$ единственный элемент множества $V$, называемый их суммой и обозначаемый $\mathbf {x} +\mathbf {y}$;
                \item Определена операция умножения векторов на скаляры $F\times V\to V$, сопоставляющая каждому элементу $\lambda$  поля $F$ и каждому элементу $\mathbf {x}$ множества $V$ единственный элемент множества $V$, обозначаемый $\lambda \cdot \mathbf {x}$  или $\lambda \mathbf {x}$;
            \end{itemize}              
            причём заданные операции удовлетворяют следующим аксиомам — аксиомам линейного (векторного) пространства:
            \begin{itemize}
                \item $\mathbf {x} +\mathbf {y} =\mathbf {y} +\mathbf {x}$ , для любых $\mathbf {x} ,\mathbf {y} \in V$ (коммутативность сложения);
                \item $\mathbf {x} +(\mathbf {y} +\mathbf {z} )=(\mathbf {x} +\mathbf {y} )+\mathbf {z}$ , для любых $\mathbf {x} ,\mathbf {y} ,\mathbf {z} \in V$ (ассоциативность сложения);
                \item существует такой элемент $\mathbf {0} \in V$, что $\mathbf {x} +\mathbf {0} =\mathbf {0} +\mathbf {x} =\mathbf {x}$ для любого $\mathbf {x} \in V$ (существование нейтрального элемента относительно сложения), называемый нулевым вектором или просто нулём пространства $V$;
                \item для любого $\mathbf {x} \in V$ существует такой элемент $-\mathbf {x} \in V$, что $\mathbf {x} +(-\mathbf {x} )=\mathbf {0}$ , называемый вектором, противоположным вектору $\mathbf {x}$ ;
                \item $\alpha (\beta \mathbf {x} )=(\alpha \beta )\mathbf {x}$  (ассоциативность умножения на скаляр);
                \item $1\cdot \mathbf {x} =\mathbf {x}$  (унитарность: умножение на нейтральный (по умножению) элемент поля $F$ сохраняет вектор).
                \item $(\alpha +\beta )\mathbf {x} =\alpha \mathbf {x} +\beta \mathbf {x}$  (дистрибутивность умножения вектора на скаляр относительно сложения скаляров);
                \item $\alpha (\mathbf {x} +\mathbf {y} )=\alpha \mathbf {x} +\alpha \mathbf {y}$ (дистрибутивность умножения вектора на скаляр относительно сложения векторов).
            \end{itemize}    
            
            \textbf{Линейным отображением (оператором)} векторного пространства $L_{K}$ над полем $K$ в векторное пространство $M_{K}$ над тем же полем $K$ (линейным оператором из $L_{K}$ в $M_{K})$ называется отображение $f\colon L_{K}\to M_{K}$, удовлетворяющее условию линейности:
            \begin{itemize}
                \item $f(x+y)=f(x)+f(y)$,
                \item $f(\alpha x)=\alpha f(x)$.
            \end{itemize}              
            для всех $x,y\in L_{K}$ и $\alpha \in K$.
            
        \subsubsection*{Базис, размерность, ранг}
            \textbf{Рангом} системы строк (столбцов) матрицы $A$ с $m$ строк и $n$ столбцов называется максимальное число линейно независимых строк.
            
            Число столбцов и строк задают \textbf{размерность} матрицы.
            
            Векторы $\mathbf {x} _{1},\mathbf {x} _{2},\dots ,\mathbf {x} _{n}$ называются линейно зависимыми, если существует их нетривиальная линейная комбинация, значение которой равно нулю; то есть $\alpha _{1}\mathbf {x} _{1}+\alpha _{2}\mathbf {x} _{2}+\ldots +\alpha _{n}\mathbf {x} _{n}=\mathbf {0}$ при некоторых коэффициентах $\alpha _{1},\alpha _{2},\ldots ,\alpha _{n}\in F$, причём хотя бы один из коэффициентов $\alpha_i$ отличен от нуля.

            В противном случае эти векторы называются линейно независимыми.

            Число элементов (мощность) максимального линейно независимого множества элементов векторного пространства не зависит от выбора этого множества. Данное число называется \textbf{рангом}, или \textbf{размерностью}, пространства, а само это множество — \textbf{базисом}. Элементы базиса именуют \textbf{базисными векторами}. Размерность пространства чаще всего обозначается символом \textbf{${\rm {dim}}$}.

        \subsubsection*{Собственные числа и собственные векторы}
            Пусть $L$ — линейное пространство над полем $K$, $A\colon L\to L$ — линейное преобразование.

            \textbf{Собственным вектором} линейного преобразования $A$ называется такой ненулевой вектор $x\in L$, что для некоторого $\lambda \in K$ $Ax=\lambda x$.

            \textbf{Собственным значением} (собственным числом) линейного преобразования $A$ называется такое число $\lambda \in K$, для которого существует собственный вектор, то есть уравнение $Ax=\lambda x$ имеет ненулевое решение $x\in L$.

            Упрощённо говоря, собственный вектор — любой ненулевой вектор $x$, который отображается в коллинеарный ему вектор $\lambda x$ оператором $A$, а соответствующий скаляр $\lambda$ называется собственным значением оператора.

        \subsubsection*{Характеристический многочлен}
            Для данной матрицы $A$, $\chi (\lambda )=\det(A-\lambda E)$, где $E$ — единичная матрица, является многочленом от $\lambda$, который называется характеристическим многочленом матрицы $A$.
    
    \subsection{Теория вероятностей}
    
        \subsubsection*{Зависимые и независимые события}
            Два события называются \textbf{независимыми}, если появление одного из них не изменяет вероятность появления другого. Например, если в цехе работают две автоматические линии, по условиям производства не взаимосвязанные, то остановки этих линий являются независимыми событиями.
            
            События называются \textbf{зависимыми}, если одно из них влияет на вероятность появления другого. Например, две производственные установки связаны единым технологическим циклом. Тогда вероятность выхода из строя одной из них зависит от того, в каком состоянии находится другая.


        \subsubsection*{Условные вероятности}
            Вероятность одного события $B$, вычисленная в предположении осуществления другого события $A$, называется условной вероятностью события $B$ и обозначается $P\{B|A\}$.
            
        \subsubsection*{Формула полной вероятности}
            Если событие $A$ наступает только при условии появления одного из событий $B_1,B_2,\ldots{B_n}$, образующих полную группу несовместных событий, то вероятность события $A$ равна сумме произведений вероятностей каждого из событий $B_1,B_2,\ldots{B_n}$ на соответствующую условную вероятность события $B_1,B_2,\ldots{B_n}$: $P\{A\}=\sum\limits_{i=1}^{n}P\{B_i\}P\{A|B_i\}$.

            При этом события $B_i,~i=1,\ldots,n$ называются гипотезами, а вероятности $P\{B_i\}$ — априорными.
            
        \subsubsection*{Математическое ожидание}
            Математическое ожидание дискретной случайной величины $X$ вычисляется как сумма произведений значений $x_i$, которые принимает случайная величина $X$, на соответствующие вероятности $p_i$: $M[X]=\sum \limits _{{i=1}}^{{\infty }}x_{i}\,p_{i}$.
            
            \textbf{Задание}. Вероятность попадания в цель при одном выстреле равна 0,8 и уменьшается с каждым выстрелом на 0,1. Составить закон распределения числа попаданий в цель, если сделано три выстрела. Найти математическое ожидание, этой случайной величины.
            
            \textbf{Решение}. Введем дискретную случайную величину $X$ = (Число попаданий в цель). X может принимать значения 0, 1, 2 и 3. Найдем соответствующие вероятности. Вероятность не попасть 3 раза: $0,2*0,3*0,4$. Вероятность не попасть 2 раза: $0,2*0,3*0,6+0,2*0,7*0,4+0,8*0,3*0,4$. И т.д. Мат. ожидание будет $0*0,2*0,3*0,4 + 1*0,2*0,3*0,6+0,2*0,7*0,4+0,8*0,3*0,4$ и т.д.
            
        \subsubsection*{Второй момент}
            Начальным моментом s-го порядка прерывной случайной величины называется сумма вида: $\alpha_s[X]=\sum \limits _{{i=1}}^{{\infty }}x_{i}^{s}\,p_{i}$.
            
            Математическое ожидание – первый начальный момент случайной величины.
            
        \subsubsection*{Неравенства Маркова и Чебышёва}
            \textbf{Неравенство Маркова} дает вероятностную оценку того, что значение неотрицательной случайной величины превзойдет некоторую константу через известное математическое ожидание. Когда никаких других данных о распределении нет, неравенство дает некоторую информацию, хотя зачастую оценка груба или тривиальна.
            
            Пусть $X$ - случайная величина, принимающая неотрицательные значения, $M(X)$ - ее конечное математическое ожидание, то для любых $a>0$ выполняется: $P(X \geq a) \leq {M(X)\over{a}}$.
            
            \textbf{Задача}: Среднее количество вызовов, поступающих на коммутатор завода в течение часа, равно 300. Оценить вероятность того, что в течение следующего часа число вызовов на коммутатор превысит 400.
            \textbf{Решение}: По условию $M(X) = 300$. Воспользуемся формулой (неравенством Маркова): $P(X \geq 400) \leq {300\over{400}} = 0,75$, т.е. вероятность того, что число вызовов превысит 400, будет не более 0,75.
            
            \textbf{Неравенство Чёбышева} показывает, что случайная величина принимает значения близкие к среднему (математическому ожиданию) и дает оценку вероятности больших отклонений.
            
            $P(|X-M(X)| \geq a) \leq {D(X)\over{a^{2}}}, a>0$
            
\section{Алгоритмы и структуры данных}

    Нужно уметь написать код для перечисленных ниже элементарных алгоритмов.

    \subsection{Оценка алгоритмов}
    
        Мы рассчитываем, что вы понимаете, какое количество операций и объём дополнительной памяти необходимы для обсуждаемых алгоритмов и из каких соображений это получается.
    
    \subsection{Простейшие алгоритмы}
    
        \subsubsection*{Поиск заданного элемента}
            
            \textbf{В отсортированном массиве:}
            
                \textbf{Бинарный поиск:}
                
                \begin{enumerate}
                    \item Определение значения элемента в середине структуры данных. Полученное значение сравнивается с ключом.
                    \item Если ключ меньше значения середины, то поиск осуществляется в первой половине элементов, иначе — во второй.
                    \item Поиск сводится к тому, что вновь определяется значение серединного элемента в выбранной половине и сравнивается с ключом.
                    \item Процесс продолжается до тех пор, пока не будет найден элемент со значением ключа или не станет пустым интервал для поиска.
                \end{enumerate}

                \begin{minted}{java}
public static int binarySearch(int arr[], int elementToSearch) {
    int firstIndex = 0;
    int lastIndex = arr.length - 1;

    while(firstIndex <= lastIndex) {
        int middleIndex = (firstIndex + lastIndex) / 2;
       
        if (arr[middleIndex] == elementToSearch) {
            return middleIndex;
        }

        else if (arr[middleIndex] < elementToSearch)
            firstIndex = middleIndex + 1;

        else if (arr[middleIndex] > elementToSearch)
        lastIndex = middleIndex - 1;
        
    }
    return -1;
}
                \end{minted}
                
                Сложность: $O(\log{n})$.
                
        
            \textbf{В неупорядоченном массиве:}
                
                \textbf{Линейный поиск:}
                
                    \begin{minted}{java}
public static int linearSearch(int arr[], int elementToSearch) {

    for (int index = 0; index < arr.length; index++) {
        if (arr[index] == elementToSearch)
            return index;
    }
    return -1;
}
                    \end{minted}
                    
                    Сложность: $O(n)$.
            
        \subsubsection*{Поиск наибольшего элемента}
        
            \textbf{Линейный поиск:}
                
                    \begin{minted}{java}
public static int linearSearch(int arr[]) {

    int maxElement = arr[0];
    for (int index = 1; index < arr.length; index++) {
        if (arr[index] > maxElement){
            maxElement = arr[index]
        }
    }
    
    return maxElement;
}   
                    \end{minted}
                    
                    Сложность: $O(n)$.
            
        \subsubsection*{Сортировка вставкой}
        
            Общая суть сортировок вставками такова:
            \begin{itemize}
                \item Перебираются элементы в неотсортированной части массива.
                \item Каждый элемент вставляется в отсортированную часть массива на то место, где он должен находиться.
            \end{itemize}

            То есть, сортировки вставками всегда делят массив на 2 части — отсортированную и неотсортированную. Из неотсортированной части извлекается любой элемент. Поскольку другая часть массива отсортирована, то в ней достаточно быстро можно найти своё место для этого извлечённого элемента. Элемент вставляется куда нужно, в результате чего отсортированная часть массива увеличивается, а неотсортированная уменьшается.
            
            Пример:
            
            6 5 3 1 8 7
            
            \underline{6} 5 3 1 8 7
            
            \underline{5} \underline{6} 3 1 8 7
            
            \underline{3} \underline{5} \underline{6} 1 8 7
            
            \underline{1} \underline{3} \underline{5} \underline{6} 8 7
            
            \underline{1} \underline{3} \underline{5} \underline{6} \underline{8}
            
            \underline{1} \underline{3} \underline{5} \underline{6} \underline{7} \underline{8}
            
            \begin{minted}{java}
public static void insertIntoSort(int[] arr) {
    int temp, j;
    for(int i = 0; i < arr.length - 1; i++){
        if (arr[i] > arr[i + 1]) {
            temp = arr[i + 1];
            arr[i + 1] = arr[i];      
            j = i;
            while (j > 0 && temp < arr[j - 1]) {
                arr[j] = arr[j - 1];               
                j--;
            }
            arr[j] = temp;             
        }        
    }
}
            \end{minted}
            
            Вычислительная сложность: $O(n^2)$.

        \subsubsection*{Сортировка пузырьком}
        
            Расположим массив сверху вниз, от нулевого элемента - к последнему.
            \textbf{Идея метода}: шаг сортировки состоит в проходе снизу вверх по массиву. По пути просматриваются пары соседних элементов. Если элементы некоторой пары находятся в неправильном порядке, то меняем их местами.
            После нулевого прохода по массиву "вверху" оказывается самый "легкий" элемент - отсюда аналогия с пузырьком. Следующий проход делается до второго сверху элемента, таким образом второй по величине элемент поднимается на правильную позицию...
            Делаем проходы по все уменьшающейся нижней части массива до тех пор, пока в ней не останется только один элемент. На этом сортировка заканчивается, так как последовательность упорядочена по возрастанию.
            
            Пример:
            
            4   4   4   4   \underline{2}    |    \underline{2}   \underline{2}   \underline{2}   \underline{2}
            
            9   9   9   2   4    |    \underline{3}   \underline{3}   \underline{3}   \underline{3}
            
            7   7   2   9   9    |    4   \underline{4}   \underline{4}   \underline{4}   
            
            6   2   7   7   7    |    9   9   \underline{6}   \underline{6}
            
            2   6   6   6   6    |    7   7   9   \underline{7}
            
            3   3   3   3   3    |    6   6   7   9
            
            \begin{minted}{java}
public int[] Sort(int[] array) {
    int i = 0;
    int goodPairsCounter = 0;
    while (true) {
        if (array[i] > array[i + 1]) {
            int q = array[i];
            array[i] = array[i + 1];
            array[i + 1] = q;
            goodPairsCounter = 0;
        } else {
            goodPairsCounter++;
        }
        i++;
        if (i == array.length - 1) {
            i = 0;
        }
        if (goodPairsCounter == array.length - 1) break;
    }
    return array;
}
            \end{minted}
            
            Вычислительная сложность: $O(n^2)$.
        
        \subsubsection*{Быстрая сортировка}
        
            \textbf{Пошаговое описание работы алгоритма быстрой сортировки:}
            \begin{enumerate}
                \item Выбрать опорный элемент из массива. Обычно опорным элементом является средний элемент.
                \item Разделить массив на два подмассива: элементы, меньше опорного и элементы, больше опорного.
                \item Рекурсивно применить сортировку к двум подмассивам.
            \end{enumerate}
            
            Пример:
            
            4 9 7  \underline{6} 2 3 8
            
            4 9* 7  \underline{6}  2 3* 8
              
            4 3 7*  \underline{6}  2* 9 8
            
            4 3 2  \underline{6} 7 9 8
                
            Дальше вызываем от двух половинок.    

            \begin{minted}{java}
public static void quickSort(int[] source, int leftBorder, int rightBorder) {
    int leftMarker = leftBorder;
    int rightMarker = rightBorder;
    int pivot = source[(leftMarker + rightMarker) / 2];
    do {
        // Двигаем левый маркер слева направо пока элемент меньше, чем pivot
        while (source[leftMarker] < pivot) {
            leftMarker++;
        }
        // Двигаем правый маркер, пока элемент больше, чем pivot
        while (source[rightMarker] > pivot) {
            rightMarker--;
        }
        // Проверим, не нужно обменять местами элементы, 
        // на которые указывают маркеры
        if (leftMarker <= rightMarker) {
            // Левый маркер будет меньше правого 
            // только если мы должны выполнить swap
            if (leftMarker < rightMarker) {
                int tmp = source[leftMarker];
                source[leftMarker] = source[rightMarker];
                source[rightMarker] = tmp;
            }
            // Сдвигаем маркеры, чтобы получить новые границы
            leftMarker++;
            rightMarker--;
        }
    } while (leftMarker <= rightMarker);

    // Выполняем рекурсивно для частей
    if (leftMarker < rightBorder) {
        quickSort(source, leftMarker, rightBorder);
    }
    
    if (leftBorder < rightMarker) {
        quickSort(source, leftBorder, rightMarker);
    }
}
            \end{minted}

            Вычислительная сложность: $O(n \log n)$.
            
        \subsubsection*{Иерархические сортировки}
            
            \textbf{Пирамидальная сортировка или сортировка кучей:}
            
            Сортировка пирамидой использует бинарное сортирующее дерево. Сортирующее дерево — это такое дерево, у которого выполнены условия:
            \begin{enumerate}
                \item Каждый лист имеет глубину либо $d$, либо $d-1$, $d$ — максимальная глубина дерева.
                \item Значение в любой вершине не меньше (другой вариант — не больше) значения её потомков.
            \end{enumerate}
            
            Удобная структура данных для сортирующего дерева — такой массив arr, что arr[0] - элемент в корне, а потомки элемента arr[i] являются arr[2i+1] и arr[2i+2].
            
            Алгоритм сортировки будет состоять из двух основных шагов:
            \begin{enumerate}
                \item Выстраиваем элементы массива в виде сортирующего дерева: $arr[i] \geq arr[2i+1]$, $arr[i] \geq arr[2i+2]$ при $0 \leq i \leq {n \over 2}$. 
                \item Будем удалять элементы из корня по одному за раз и перестраивать дерево. То есть на первом шаге обмениваем arr[0] и arr[n-1], преобразовываем arr[0], arr[1], .. , arr[n-2] в сортирующее дерево. Затем переставляем arr[0] и arr[n-2], преобразовываем arr[0], arr[1], .. , arr[n-3] в сортирующее дерево. Процесс продолжается до тех пор, пока в сортирующем дереве не останется один элемент. Тогда arr - — упорядоченная последовательность.
            \end{enumerate}
            
            Пример:
            
            5 3 4 1 2   - Строим кучу из исходного массива
            
            \underline{2} 3 4 1 \underline{5}   - Меняем местами первый и последний элементы
            
            \underline{4} 3 2 1 5   - Строим кучу из первых четырёх элементов
            
            \underline{1} 3 2 \underline{4} 5   - Меняем местами первый и четвёртый элементы
            
            \underline{3} 1 2 4 5   - Строим кучу из первых трёх элементов
            
            \underline{2} 1 \underline{3} 4 5   - Меняем местами первый и третий элементы
            
            \underline{2} 1 3 4 5   - Строим кучу из двух элементов
            
            \underline{1} \underline{2} 3 4 5   - Меняем местами первый и второй элементы
            
            \begin{minted}{java}
/*
 * Класс для сортировки массива целых чисел с помощью кучи.
 * Методы в классе написаны в порядке их использования. Для сортировки 
 * вызывается статический метод sort(int[] a)
 */
class HeapSort {
    /*
     * Размер кучи. Изначально равен размеру сортируемого массива
     */
    private static int heapSize;
    
    /*
     * Сортировка с помощью кучи.
     * Сначала формируется куча:
     * Теперь максимальный элемент массива находится в корне кучи. Его нужно 
     * поменять местами с последним элементом и убрать из кучи (уменьшить 
     * размер кучи на 1). Теперь в корне кучи находится элемент, который раньше
     * был последним в массиве. Нужно переупорядочить кучу так, чтобы 
     * выполнялось основное условие кучи - a[parent]>=a[child].
     * После этого в корне окажется максимальный из оставшихся элементов.
     * Повторить до тех пор, пока в куче не останется 1 элемент
     */
    public static void sort(int[] a) {
        buildHeap(a);
        while (heapSize > 1) {
            swap(a, 0, heapSize - 1);
            heapSize--;
            heapify(a, 0);
        }
    }
    
    /*
     * Построение кучи. Поскольку элементы с номерами начиная с a.length / 2 + 1
     * это листья, то нужно переупорядочить поддеревья с корнями в индексах
     * от 0 до a.length / 2 (метод heapify вызывать в порядке убывания индексов)
     */
    private static void buildHeap(int[] a) {
        heapSize = a.length;
        for (int i = a.length / 2; i >= 0; i--) {
            heapify(a, i);
        }
    }
    
    /*
     * Переупорядочивает поддерево кучи начиная с узла i так, чтобы выполнялось 
     * основное свойство кучи - a[parent] >= a[child].
     */
    private static void heapify(int[] a, int i) {
        int l = left(i);
        int r = right(i);
        int largest = i;
        if (l < heapSize && a[i] < a[l]) {
            largest = l;
        } 
        if (r < heapSize && a[largest] < a[r]) {
            largest = r;
        }
        if (i != largest) {
            swap(a, i, largest);
            heapify(a, largest);
        }
    }
    
    /*
     * Возвращает индекс правого потомка текущего узла
     */
    private static int right(int i) {
        return 2 * i + 2;
    }
    
    /*
     * Возвращает индекс левого потомка текущего узла
     */
    private static int left(int i) {
        return 2 * i + 1;
    }
    
    /*
     * Меняет местами два элемента в массиве
     */
    private static void swap(int[] a, int i, int j) {
        int temp = a[i];
        a[i] = a[j];
        a[j] = temp;
    }

}
            \end{minted}
            
            Cложность: $O(n \log n)$.
            
    \subsection{Простейшие структуры данных}
    
        \subsubsection*{Массив}
            Массив — структура данных, хранящая набор значений (элементов массива), идентифицируемых по индексу или набору индексов, принимающих целые (или приводимые к целым) значения из некоторого заданного непрерывного диапазона. 
            
            Особенностью массива как структуры данных (в отличие, например, от связного списка) является константная вычислительная сложность доступа к элементу массива по индексу. Имеет константную длину.
            
        \subsubsection*{Список}
            Связный список — базовая динамическая структура данных, состоящая из узлов, каждый из которых содержит как собственно данные, так и одну или две ссылки («связки») на следующий и/или предыдущий узел списка. Принципиальным преимуществом перед массивом является структурная гибкость: порядок элементов связного списка может не совпадать с порядком расположения элементов данных в памяти компьютера, а порядок обхода списка всегда явно задаётся его внутренними связями.
            
        \subsubsection*{Стек}
            Стек — абстрактный тип данных, представляющий собой список элементов, организованных по принципу LIFO (англ. last in — first out, «последним пришёл — первым вышел»).

            Чаще всего принцип работы стека сравнивают со стопкой тарелок: чтобы взять вторую сверху, нужно снять верхнюю.
            
            Зачастую стек реализуется в виде однонаправленного списка (каждый элемент в списке содержит помимо хранимой информации в стеке указатель на следующий элемент стека).
            
        \subsubsection*{Очередь}
            Очередь — абстрактный тип данных с дисциплиной доступа к элементам «первый пришёл — первый вышел» (FIFO, англ. first in, first out). Добавление элемента (принято обозначать словом enqueue — поставить в очередь) возможно лишь в конец очереди, выборка — только из начала очереди (что принято называть словом dequeue — убрать из очереди), при этом выбранный элемент из очереди удаляется.
            
\section{Программирование}     

    Нужно знать базовые принципы одного из «традиционных» (C, C++, Java, Python и др.) языков программирования.
    
    \subsubsection*{Основы синтаксиса}
        \begin{itemize}
            \item Язык Java различает прописные и строчные буквы.
            \item Каждая команда (оператор) в языке Java должна заканчиваться точкой с запятой.
            \item Программа на Java состоит из одного или нескольких классов. Абсолютно вся функциональная часть программы (т.е. то, что она делает) должна быть помещена в методы тех или иных классов.
            \item Хотя бы в одном из классов должен существовать метод main(). Именно этот метод и будет выполняться первым.
            \item В простейшем случае программа может состоять из одного (или даже ни одного) пакета, одного класса внутри пакета и единственного метода main() внутри класса. Команды программы будут записываться между строчкой         \begin{minted}{java}
public static void main(String[] args) { }
		        \end{minted} 
		        и закрывающей фигурной скобкой, обозначающей окончание тела метода.
        \end{itemize}

    \subsubsection*{Переменные}
        \begin{itemize}
            \item Целочисленные (к ним относятся byte, short, int, long).
            \item С плавающей точкой (к ним относятся float, double).
            \item Символы (char).
            \item Логические (boolean).
        \end{itemize}

    \subsubsection*{Условные выражения}
        \begin{itemize}
            \item Условный оператор if. Если логическое выражение в скобках правдиво, то выполняется блок кода в фигурных скобках {} после if. Если логическое выражение принимает значение false, то ничего не происходит.
            \item Условный оператор if-else. Конструкция if-else отличается от предыдущей тем, что если логическое выражение в круглых скобках принимает значение false, то выполняется блок кода, находящийся в фигурных скобках после ключевого слова else.
            \item Условный оператор switch — case. Условный оператор switch — case удобен в тех случаях, когда количество вариантов очень много и писать для каждого if-else очень долго. Конструкция имеет следующий вид:
                \begin{minted}{java}
    switch (expression) {
      case value1: 
        //блок кода 1;
        break;
      case value2: 
        //блок кода 2;  
        break;
        ...  
      case valueN: 
        //блок кода N;  
        break;  
      default:  
        //блок N+1;
   }
		        \end{minted} 
        \end{itemize}
        
    \subsubsection*{Циклы}
        \begin{itemize}
            \item \textbf{Цикл for}.
                \begin{minted}{java}
  for (int i = 1; i < 9; i++)
{
    // действия
}
		        \end{minted}
		    \item \textbf{Цикл do} сначала выполняет код цикла, а потом проверяет условие в инструкции while. И пока это условие истинно,цикл повторяется. Например:
                \begin{minted}{java}
int j = 7;
do{
    System.out.println(j);
    j--;
}
while (j > 0);
		        \end{minted}  
		   \item \textbf{Цикл while} сразу проверяет истинность некоторого условия, и если условие истинно, то код цикла выполняется. Например:    
                \begin{minted}{java}
int j = 6;
while (j > 0){
 
    System.out.println(j);
    j--;
}
		        \end{minted}  
           \item Оператор \textbf{break} позволяет выйти из цикла в любой его момент, даже если цикл не закончил свою работу.
           \item Чтобы цикл не завершался, а просто переходил к следующей итерации, используем оператор \textbf{continue}.
        \end{itemize}
        
    \subsubsection*{Массивы}
                \begin{minted}{java}
// Объявление массива.
int[] myArray;

// Cоздание, то есть, выделение памяти 
// для массива на 10 элементов типа int.
myArray = new int[10];
		        \end{minted}      
    
    \subsubsection*{Функции}
        Метод — это именованный блок кода, который объявляется внутри класса и может быть использован многократно.

        Хорошо написанный метод решает одну практическую задачу: находит квадратный корень из числа (как штатный метод sqrt() в Java), преобразует число в строку (метод toString()), присваивает значения полям объекта и так далее.

        Новый метод сначала объявляют и определяют, затем вызывают для нужного объекта или класса.
        
        Методы могут возвращать или не возвращать значения, могут вызываться с указанием параметров или без. Тип возвращаемых данных указывают при объявлении метода — перед его именем.

        В примере ниже метод должен найти большее из двух целых чисел, поэтому тип возвращаемого значения — int:
        
        \begin{minted}{java}
// Заголовок метода.        
public static int maxFinder(int a, int b) { 
    // Ниже — тело метода.
    int max;
    if (a < b)
        max = b;
    else
        max = a;
    return max;
}
        \end{minted}      
    
    \subsubsection*{Рекурсия}
        \begin{minted}{java}
private int factorial(int n) {
    int result = 1;
    if (n == 1 || n == 0) {
        return result;
    }
    result = n * factorial(n-1);
    return result;
}
        \end{minted} 
        
    \subsubsection*{Динамическая память}
        Динамическое распределение памяти — способ выделения оперативной памяти компьютера для объектов в программе, при котором выделение памяти под объект осуществляется во время выполнения программы.
        
        \textbf{Куча} — это хранилище памяти, также расположенное в ОЗУ, которое допускает динамическое выделение памяти и не работает по принципу стека: это просто склад для ваших переменных. Когда вы выделяете в куче участок памяти для хранения переменной, к ней можно обратиться не только в потоке, но и во всем приложении. Именно так определяются глобальные переменные. По завершении приложения все выделенные участки памяти освобождаются. Размер кучи задаётся при запуске приложения, но, в отличие от стека, он ограничен лишь физически, и это позволяет создавать динамические переменные.

        Вы взаимодействуете с кучей посредством ссылок, обычно называемых указателями — это переменные, чьи значения являются адресами других переменных. Создавая указатель, вы указываете на местоположение памяти в куче, что задаёт начальное значение переменной и говорит программе, где получить доступ к этому значению. Из-за динамической природы кучи ЦП не принимает участия в контроле над ней; в языках без сборщика мусора (C, C++) разработчику нужно вручную освобождать участки памяти, которые больше не нужны. Если этого не делать, могут возникнуть утечки и фрагментация памяти, что существенно замедлит работу кучи.

        В сравнении со стеком, куча работает медленнее, поскольку переменные разбросаны по памяти, а не сидят на верхушке стека. Некорректное управление памятью в куче приводит к замедлению её работы; тем не менее, это не уменьшает её важности — если вам нужно работать с динамическими или глобальными переменными, пользуйтесь кучей.
    
    \subsubsection*{Стек}
        \textbf{Стек} — это область оперативной памяти, которая создаётся для каждого потока. Он работает в порядке LIFO (Last In, First Out),  то есть последний добавленный в стек кусок памяти будет первым в очереди на вывод из стека. Каждый раз, когда функция объявляет новую переменную, она добавляется в стек, а когда эта переменная пропадает из области видимости (например, когда функция заканчивается), она автоматически удаляется из стека. Когда стековая переменная освобождается, эта область памяти становится доступной для других стековых переменных.

        Из-за такой природы стека управление памятью оказывается весьма логичным и простым для выполнения на ЦП; это приводит к высокой скорости, в особенности потому, что время цикла обновления байта стека очень мало, т.е. этот байт скорее всего привязан к кэшу процессора. Тем не менее, у такой строгой формы управления есть и недостатки. Размер стека — это фиксированная величина, и превышение лимита выделенной на стеке памяти приведёт к переполнению стека. Размер задаётся при создании потока, и у каждой переменной есть максимальный размер, зависящий от типа данных. Это позволяет ограничивать размер некоторых переменных (например, целочисленных), и вынуждает заранее объявлять размер более сложных типов данных (например, массивов), поскольку стек не позволит им изменить его. Кроме того, переменные, расположенные на стеке, всегда являются локальными.

        В итоге стек позволяет управлять памятью наиболее эффективным образом — но если вам нужно использовать динамические структуры данных или глобальные переменные, то стоит обратить внимание на кучу.

\end{document}